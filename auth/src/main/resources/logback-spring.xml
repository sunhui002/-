<configuration>

<!--    DEBUG-->
<!--    INFO-->
<!--    WARNING-->
<!--    ERROR-->
<!--    CRITICAL-->
    <!--定义日志文件的存储地址 勿在 LogBack 的配置中使用相对路径 -->
    <property name="LOG_HOME" value="logs" />
    <property name="SYS_NAME" value="system" />
    <property name="DATA_NAME" value="data" />
    <property name="APP_LOGS_FILENAME" value="app" />
    <property name="EVENT_LOGS_FILENAME" value="event_loss_data" />
    <!--  <springProperty scope="context" name="APP_LOGS_FILENAME" source="logback.filename.applogs"/>
     <springProperty scope="context" name="EVENT_LOGS_FILENAME" source="logback.filename.eventlogs"/> -->

    <appender name="CONSOLE"
              class="ch.qos.logback.core.ConsoleAppender">
        <layout class="ch.qos.logback.classic.PatternLayout">
            <pattern>[%d] [%-5level] [%thread] [%logger] - %msg%n</pattern>
        </layout>
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>info</level>
        </filter>
    </appender>

    <appender name="FILE"
              class="ch.qos.logback.core.rolling.RollingFileAppender">
        <rollingPolicy
                class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!--日志文件输出的文件名 -->
            <FileNamePattern>${LOG_HOME}/${SYS_NAME}/${APP_LOGS_FILENAME}.%d{yyyy-MM-dd}.log
            </FileNamePattern>
            <!--日志文件保留天数 -->
            <MaxHistory>10</MaxHistory>
        </rollingPolicy>

        <layout class="ch.qos.logback.classic.PatternLayout">
            <pattern>[%d] [%-5level] [%thread] [%logger] - %msg%n</pattern>
        </layout>
        <!--日志文件最大的大小 -->
        <triggeringPolicy
                class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">
            <MaxFileSize>100MB</MaxFileSize>
        </triggeringPolicy>
    </appender>


    <!-- 业务日志：写入kafka -->
    <appender name="KAFKA-EVENTS"
              class="com.example.auth.config.KafkaAppender">
        <layout class="ch.qos.logback.classic.PatternLayout">
            <pattern>%msg</pattern>
        </layout>
    </appender>

    <appender name="ASYNC-KAFKA-EVENTS"
              class="ch.qos.logback.classic.AsyncAppender">
        <discardingThreshold>0</discardingThreshold>
        <queueSize>2048</queueSize>
        <appender-ref ref="KAFKA-EVENTS" />
    </appender>

    <logger name="kafka-event" additivity="false">
        <appender-ref ref="ASYNC-KAFKA-EVENTS" />
    </logger>

    <!-- 业务日志：异常 写入本地 -->
    <appender name="LOCAL"
              class="ch.qos.logback.core.rolling.RollingFileAppender">
        <rollingPolicy
                class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"><!-- 基于时间的策略 -->
            <fileNamePattern>${LOG_HOME}/${DATA_NAME}/${EVENT_LOGS_FILENAME}.%d{yyyy-MM-dd}.log
            </fileNamePattern>
            <!-- 日志文件保留天数 -->
            <MaxHistory>10</MaxHistory>
        </rollingPolicy>
        <triggeringPolicy
                class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">
            <!-- 文件大小触发重写新文件 -->
            <MaxFileSize>100MB</MaxFileSize>
            <!-- <totalSizeCap>10GB</totalSizeCap> -->
        </triggeringPolicy>
        <encoder>
            <charset>UTF-8</charset>
            <pattern>[%d] [%-5level] [%thread] [%logger] - %msg%n</pattern>
        </encoder>
    </appender>
    <appender name="ASYNC-LOCAL"
              class="ch.qos.logback.classic.AsyncAppender">
        <discardingThreshold>0</discardingThreshold>
        <queueSize>2048</queueSize>
        <appender-ref ref="LOCAL" />
    </appender>

    <!--万一kafka队列不通,记录到本地 -->
    <logger name="local" additivity="false">
        <appender-ref ref="ASYNC-LOCAL" />
    </logger>

    <root level="INFO">
        <appender-ref ref="CONSOLE" />
        <appender-ref ref="FILE" />
    </root>
    <logger name="org.apache.kafka" level="DEBUG">
    </logger>
    <logger name="org.apache.zookeeper" level="DEBUG">
    </logger>

</configuration>
